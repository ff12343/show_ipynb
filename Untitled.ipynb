{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = [640]\n",
    "# img_size.extend([img_size[-1]] * (2 - len(img_size)))\n",
    "# (2 - len(img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[640]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[img_size[-1]] * (2 - len(img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "path = 'D:\\\\My_Demo\\\\Dateset\\\\COCO123\\\\coco2017\\\\images\\\\train2017'\n",
    "# path = 'D:\\\\My_Demo\\\\Dateset\\\\COCO123\\\\coco2017\\\\train2017.txt'\n",
    "img_formats = ['bmp', 'jpg', 'jpeg', 'png', 'tif', 'tiff', 'dng', 'webp', 'mpo']  # acceptable image suffixes\n",
    "try:\n",
    "    f = []  # image files\n",
    "    for p in path if isinstance(path, list) else [path]:\n",
    "        \n",
    "        p = Path(p)  # os-agnostic\n",
    "        if p.is_dir():  # dir\n",
    "            f += glob.glob(str(p / '**' / '*.*'), recursive=True)\n",
    "            # f = list(p.rglob('**/*.*'))  # pathlib\n",
    "        elif p.is_file():  # file\n",
    "            with open(p, 'r') as t:\n",
    "                t = t.read().strip().splitlines()\n",
    "                parent = str(p.parent) + os.sep\n",
    "                f += [x.replace('./', parent) if x.startswith('./') else x for x in t]  # local to global path\n",
    "                # f += [p.parent / x.lstrip(os.sep) for x in t]  # local to global path (pathlib)\n",
    "        else:\n",
    "            raise Exception(f'{prefix}{p} does not exist')\n",
    "    img_files = sorted([x.replace('/', os.sep) for x in f if x.split('.')[-1].lower() in img_formats])\n",
    "    # self.img_files = sorted([x for x in f if x.suffix[1:].lower() in img_formats])  # pathlib\n",
    "    assert img_files, f'{prefix}No images found'\n",
    "except Exception as e:\n",
    "    raise Exception(f'{prefix}Error loading data from {path}: {e}\\nSee {help_url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = img_files\n",
    "sa, sb = os.sep + 'images' + os.sep, os.sep + 'labels' + os.sep  # /images/, /labels/ substrings\n",
    "label_files = ['txt'.join(x.replace(sa, sb, 1).rsplit(x.split('.')[-1], 1)) for x in img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "def cache_labels(path=Path('./labels.cache'), prefix=''):\n",
    "    # Cache dataset labels, check images and read shapes\n",
    "    x = {}  # dict\n",
    "    nm, nf, ne, nc = 0, 0, 0, 0  # number missing, found, empty, duplicate\n",
    "    pbar = tqdm(zip(img_files, label_files), desc='Scanning images', total=len(img_files))\n",
    "    for i, (im_file, lb_file) in enumerate(pbar):\n",
    "\n",
    "        # verify images\n",
    "        im = Image.open(im_file)\n",
    "        im.verify()  # PIL verify\n",
    "        shape = exif_size(im)  # image size\n",
    "        segments = []  # instance segments \n",
    "        assert (shape[0] > 9) & (shape[1] > 9), f'image size {shape} <10 pixels'\n",
    "        assert im.format.lower() in img_formats, f'invalid image format {im.format}'\n",
    "\n",
    "        \n",
    "        # verify labels\n",
    "        if os.path.isfile(lb_file):\n",
    "            nf += 1  # label found\n",
    "            with open(lb_file, 'r') as f:\n",
    "                l = [x.split() for x in f.read().strip().splitlines()]\n",
    "                if any([len(x) > 8 for x in l]):  # is segment\n",
    "                    classes = np.array([x[0] for x in l], dtype=np.float32)\n",
    "                    segments = [np.array(x[1:], dtype=np.float32).reshape(-1, 2) for x in l]  # (cls, xy1...)\n",
    "                    print('segment',segments)\n",
    "                    l = np.concatenate((classes.reshape(-1, 1), segments2boxes(segments)), 1)  # (cls, xywh)\n",
    "                l = np.array(l, dtype=np.float32)\n",
    "                print(l)\n",
    "            if len(l):\n",
    "                assert l.shape[1] == 5, 'labels require 5 columns each'\n",
    "                assert (l >= 0).all(), 'negative labels'\n",
    "                assert (l[:, 1:] <= 1).all(), 'non-normalized or out of bounds coordinate labels'\n",
    "                assert np.unique(l, axis=0).shape[0] == l.shape[0], 'duplicate labels'\n",
    "            else:\n",
    "                ne += 1  # label empty\n",
    "                l = np.zeros((0, 5), dtype=np.float32)\n",
    "        else:\n",
    "            nm += 1  # label missing\n",
    "            l = np.zeros((0, 5), dtype=np.float32)\n",
    "        x[im_file] = [l, shape, segments]\n",
    "        break\n",
    "\n",
    "\n",
    "        pbar.desc = f\"{prefix}Scanning '{path.parent / path.stem}' images and labels... \" \\\n",
    "                    f\"{nf} found, {nm} missing, {ne} empty, {nc} corrupted\"\n",
    "    pbar.close()\n",
    "\n",
    "    if nf == 0:\n",
    "        print(f'{prefix}WARNING: No labels found in {path}. See {help_url}')\n",
    "\n",
    "    x['hash'] = get_hash(self.label_files + self.img_files)\n",
    "    x['results'] = nf, nm, ne, nc, i + 1\n",
    "    x['version'] = 0.1  # cache version\n",
    "    torch.save(x, path)  # save for next time\n",
    "    logging.info(f'{prefix}New cache created: {path}')\n",
    "    return x\n",
    "def exif_size(img):\n",
    "    # Returns exif-corrected PIL size\n",
    "    s = img.size  # (width, height)\n",
    "    try:\n",
    "        rotation = dict(img._getexif().items())[orientation]\n",
    "        if rotation == 6:  # rotation 270\n",
    "            s = (s[1], s[0])\n",
    "        elif rotation == 8:  # rotation 90\n",
    "            s = (s[1], s[0])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning images:   0%|                                                                      | 0/118287 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45.        0.479492  0.688771  0.955609  0.5955  ]\n",
      " [45.        0.736516  0.247188  0.498875  0.476417]\n",
      " [50.        0.637063  0.732938  0.494125  0.510583]\n",
      " [45.        0.339438  0.418896  0.678875  0.7815  ]\n",
      " [49.        0.646836  0.132552  0.118047  0.096937]\n",
      " [49.        0.773148  0.129802  0.090734  0.097229]\n",
      " [49.        0.668297  0.226906  0.131281  0.146896]\n",
      " [49.        0.642859  0.079219  0.148063  0.148062]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_hash' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-01b020887a6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# re-cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-387df2264f76>\u001b[0m in \u001b[0;36mcache_labels\u001b[1;34m(path, prefix)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{prefix}WARNING: No labels found in {path}. See {help_url}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hash'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_files\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'results'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mne\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'version'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m  \u001b[1;31m# cache version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_hash' is not defined"
     ]
    }
   ],
   "source": [
    "cache_path = (p if p.is_file() else Path(label_files[0]).parent).with_suffix('.cache')  # cached labels\n",
    "prefix = ''\n",
    "if cache_path.is_file():\n",
    "    cache, exists = torch.load(cache_path), True  # load\n",
    "    if cache['hash'] != get_hash(self.label_files + self.img_files) or 'version' not in cache:  # changed\n",
    "        cache, exists = cache_labels(cache_path, prefix), False  # re-cache\n",
    "else:\n",
    "    cache, exists = cache_labels(cache_path, prefix), False  # cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.333333'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 3/3/3\n",
    "format(3/3/3, '.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'colorstr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-be74bee218d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolorstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{task}: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'colorstr' is not defined"
     ]
    }
   ],
   "source": [
    "prefix=colorstr(f'{task}: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, float found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-0cc5a5efeb69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlist1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m45.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.479492\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.688771\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.955609\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5955\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, float found"
     ]
    }
   ],
   "source": [
    "list1 = [45.,0.479492,0.688771,0.955609,0.5955 ]\n",
    "' '.join(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img, name = 'img'):\n",
    "    cv2.namedWindow(name, cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO | cv2.WINDOW_GUI_EXPANDED)\n",
    "    cv2.imshow(name, img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def image_json_adjustment(path, json_path):   #传入待标注图片的路径，模板路径，模板json文件的路径（需要手动标注一张json文件做为模板）\n",
    "\n",
    "    with open(json_path, \"r\", encoding='utf-8') as jsonFile:\n",
    "        json_data = json.load(jsonFile)\n",
    "\n",
    "    file_name,json_point_offset = [],[]\n",
    "    for _,_,file_name in os.walk(path):\n",
    "        break\n",
    "\n",
    "    for i, name in enumerate(file_name):\n",
    "        image_path = path + name\n",
    "        json_data_path = path + name[:-4] + '.json'\n",
    "        image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), -1)\n",
    "\n",
    "        with open(image_path,'rb') as image_file:\n",
    "            image_text_data = image_file.read()\n",
    "            image_text_bytes = base64.b64encode(image_text_data)\n",
    "            image_text_tring = image_text_bytes.decode('utf-8')\n",
    "\n",
    "            json_data['imageData'] = image_text_tring       #修改json文件对应的图片\n",
    "            json_data[\"imagePath\"] = name                   #修改名称\n",
    "            json_data[\"imageHeight\"] = image.shape[0]          #修改高宽\n",
    "            json_data[\"imageWidth\"] = image.shape[1]\n",
    "\n",
    "            with open(json_data_path, \"w\") as jsonFile:\n",
    "                json.dump(json_data, jsonFile, ensure_ascii=False)\n",
    "\n",
    "json_path = 'C:\\\\Users\\\\28104\\\\Desktop\\\\dateset\\\\静态2000\\新建文件夹\\\\MyImage - 20200907081503004.json'\n",
    "path = 'C:\\\\Users\\\\28104\\\\Desktop\\\\dateset\\\\静态2000\\\\DN300\\\\'\n",
    "image_json_adjustment(path, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = 'C:\\\\Users\\\\28104\\\\Desktop\\\\dateset\\\\静态2000\\\\DN300\\\\MyImage - 20200907081503004.jpg'\n",
    "img = cv2.imdecode(np.fromfile(img1, dtype=np.uint8), -1)\n",
    "show_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_json_to_image(image_path, json_base_path, json_copy_path):   #传入待标注图片的路径，模板路径，模板json文件的路径（需要手动标注一张json文件做为模板）\n",
    "\n",
    "    with open(json_base_path, \"r\", encoding='utf-8') as jsonFile:\n",
    "        json_data = json.load(jsonFile)\n",
    "    \n",
    "    name = image_path.split('\\\\')[-1]\n",
    "    image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), -1)\n",
    "\n",
    "    with open(image_path,'rb') as image_file:\n",
    "        image_text_data = image_file.read()\n",
    "        image_text_bytes = base64.b64encode(image_text_data)\n",
    "        image_text_tring = image_text_bytes.decode('utf-8')\n",
    "\n",
    "        json_data['imageData'] = image_text_tring       #修改json文件对应的图片\n",
    "        json_data[\"imagePath\"] = name                   #修改名称\n",
    "        json_data[\"imageHeight\"] = image.shape[0]          #修改高宽\n",
    "        json_data[\"imageWidth\"] = image.shape[1]\n",
    "\n",
    "        with open(json_copy_path, \"w\") as jsonFile:\n",
    "            json.dump(json_data, jsonFile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy  20210426_103842_img.json to  20210426_103845_img.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import base64\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "path = 'C:\\\\Users\\\\28104\\\\Desktop\\\\dateset\\\\动态数据2000\\\\DN450\\\\'\n",
    "files = os.listdir(path)\n",
    "files_jpg = []\n",
    "files_json = []\n",
    "for i in files:\n",
    "    if i.split('.')[1] == 'jpg':\n",
    "        files_jpg.append(i)\n",
    "    elif i.split('.')[1] == 'json':\n",
    "        files_json.append(i)\n",
    "    else:\n",
    "        print(i)\n",
    "\n",
    "lastfileIdx = len(files_json) - 1\n",
    "if files_json[lastfileIdx].split('.')[0] == files_jpg[lastfileIdx].split('.')[0]:\n",
    "    print('copy ',files_json[lastfileIdx], 'to ', files_jpg[lastfileIdx+1].split('.')[0] + '.json')\n",
    "    image_path = path + files_jpg[lastfileIdx+1]\n",
    "    json_base_path = path + files_json[lastfileIdx]\n",
    "    json_copy_path = path + files_jpg[lastfileIdx+1].split('.')[0] + '.json'\n",
    "    last_json_to_image(image_path, json_base_path, json_copy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1600000, 1024000])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "img_size = 640\n",
    "stride = 2\n",
    "pad = 0\n",
    "shapes = [2500, 1600]\n",
    "batch_shapes = np.ceil(np.array(shapes) * img_size / stride + pad).astype(np.int) * stride\n",
    "batch_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil\n",
    "\n",
    "def mymovefile(srcfile,dstfile):\n",
    "    if not os.path.isfile(srcfile):\n",
    "        print(\"%s not exist!\"%(srcfile)) \n",
    "    else:\n",
    "        fpath,fname=os.path.split(dstfile)    #分离文件名和路径\n",
    "        if not os.path.exists(fpath):\n",
    "            os.makedirs(fpath)                #创建路径\n",
    "        shutil.move(srcfile,dstfile)          #移动文件\n",
    "\n",
    "datepath = 'C:\\\\Users\\\\28104\\\\Desktop\\\\dateset\\\\静态2000原始标注 - 副本\\\\DN800\\\\'\n",
    "files = os.listdir(datepath)\n",
    "files_jpg = []\n",
    "files_json = []\n",
    "for i in files:\n",
    "    if i.split('.')[1] == 'jpg':\n",
    "        files_jpg.append(i)\n",
    "    elif i.split('.')[1] == 'json':\n",
    "        files_json.append(i)\n",
    "    else:\n",
    "        print(i)\n",
    "\n",
    "Valdstpath = datepath + '\\\\val\\\\'\n",
    "Traindstpath = datepath + '\\\\train\\\\'\n",
    "\n",
    "for i in range(len(files_json)):\n",
    "    if files_json[i].split('.')[0] == files_jpg[i].split('.')[0]:\n",
    "        if i % 10 == 0:# val\n",
    "            mymovefile(datepath+files_json[i], Valdstpath + files_json[i].split('//')[-1])\n",
    "            mymovefile(datepath+files_jpg[i], Valdstpath + files_jpg[i].split('//')[-1])\n",
    "        else:\n",
    "            mymovefile(datepath+files_json[i], Traindstpath + files_json[i].split('//')[-1])\n",
    "            mymovefile(datepath+files_jpg[i], Traindstpath + files_jpg[i].split('//')[-1])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
